{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Nework\n",
    "Here we try to write a simple neural network to understand how backpropagation algorithm works :)\n",
    "## Now we create a simple one layer newtork "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue our feedforward network and make it a complete neural network that can predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#activation funcion\n",
    "\n",
    "#deivative of activation funcion\n",
    "\n",
    "#class of your neural network\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    #set features of your neural network\n",
    "    def __init__(self, x, y):\n",
    "        self.input      = \n",
    "        self.weights1   = \n",
    "        self.weights2   =                  \n",
    "        self.y          = \n",
    "        self.output     = \n",
    "    #feedfarward function \n",
    "    def feedforward(self):\n",
    "        self.layer1 = \n",
    "        self.output = \n",
    "    #backpropagate the error\n",
    "    def backprop(self):\n",
    "        # application of the chain rule to find derivative of the Error with respect to weights2 and weights1\n",
    "        d_weights2 = \n",
    "        d_weights1 =\n",
    "\n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        self.weights1 = \n",
    "        self.weights2 =\n",
    "\n",
    "#Test what you have done :D \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X = np.array([[0,0],\n",
    "                  [0,1],\n",
    "                  [1,0],\n",
    "                  [1,1]])\n",
    "    y = np.array([[0],[1],[1],[0]])\n",
    "   \n",
    "    nn = # make instance of your NerualNetwork class\n",
    "   \n",
    "    #do the iteration for learning\n",
    "   \n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22584974 0.35432398]\n",
      " [0.71881711 0.46009808]]\n",
      "[[0.0970963  0.37812284]\n",
      " [0.6686741  0.47623547]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#activation funcion\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1+ np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)\n",
    "#class of your neural network\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    #set features of your neural network\n",
    "    def __init__(self, x, y):\n",
    "        self.input      = x\n",
    "        self.weights1   = np.random.rand(self.input.shape[1],2) \n",
    "        self.weights2   = np.random.rand(2,1)                 \n",
    "        self.y          = y\n",
    "        self.output     = np.zeros(self.y.shape)\n",
    "    #feedfarward function \n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "    #backpropagate the error\n",
    "    def backprop(self):\n",
    "        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
    "        d_weights2 = np.dot(self.layer1.T, ((self.y - self.output) * sigmoid_derivative(self.output)))\n",
    "        d_weights1 = np.dot(self.input.T,  (np.dot((self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
    "\n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2\n",
    "\n",
    "#Test what you have done :D \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X = np.array([[0,0],\n",
    "                  [0,1],\n",
    "                  [1,0],\n",
    "                  [1,1]])\n",
    "    y = np.array([[0],[1],[1],[0]])\n",
    "    \n",
    "    nn = NeuralNetwork(X,y)\n",
    "    print(nn.weights1)\n",
    "\n",
    "    for i in range(100):\n",
    "        nn.feedforward()\n",
    "        nn.backprop()\n",
    "\n",
    "    #print(nn.y - nn.output)\n",
    "    print(nn.weights1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Useful Libraries\n",
    "Simple Example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mahsa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "clf = MLPClassifier()\n",
    "clf.fit(X, y)                         \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR Function\n",
    "Let us start with a simple example of Boolean OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np\n",
    "\n",
    "X_training=[[0,0],[1,0],[0,1],[1,1]]\n",
    "y_training=[0,1,1,1]\n",
    "mynet = MLPClassifier()\n",
    "mynet.fit(X_training,y_training)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mahsa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np\n",
    "\n",
    "X_training=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            1,\n",
    "            1,\n",
    "            0\n",
    "           ]\n",
    "mlp = MLPClassifier() # set the method\n",
    "mlp.fit(X_training, y_training)  \n",
    "mlp.predict([[1,1]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice: Bipolar OR\n",
    "\n",
    "Instead of {0, 1}, we can also change the value into bipolar {-1, +1}. Try the following OR gate using Perceptron and MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_training=[[1, 1], \n",
    "            [1, -1],\n",
    "            [-1, 1],\n",
    "            [-1, -1]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            1,\n",
    "            1,\n",
    "            -1\n",
    "           ]\n",
    "X_testing=X_training\n",
    "y_true=y_training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Networks\n",
    "\n",
    "The following code is the example of how you will use Multi-Layer Perceptron (MLP) Neural Network to train, predict. You can also get the weights of the Neural Network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0]\n",
      "[(2, 100), (100, 1)]\n",
      "[array([[ 1.14517682e-01,  4.41480569e-02, -4.61609935e-06,\n",
      "        -2.51327879e-01,  2.85634743e-01,  2.87470210e-01,\n",
      "         1.28830789e-01, -3.30806400e-01,  1.20621380e-01,\n",
      "         6.43939743e-07, -6.64369264e-02, -2.06172800e-01,\n",
      "        -2.29836036e-02, -1.79203580e-03,  5.11040231e-02,\n",
      "         3.95837932e-07,  3.76345871e-07,  1.11386757e-01,\n",
      "        -2.53238858e-01, -1.38669532e-07,  6.78403614e-02,\n",
      "        -8.91174013e-03,  1.20620716e-01,  4.07732523e-03,\n",
      "        -4.68671310e-03, -1.62292251e-07, -2.71990641e-01,\n",
      "        -2.06199039e-02,  1.47531966e-01,  2.16918239e-05,\n",
      "         2.30278603e-01, -2.78854818e-01,  3.01411202e-01,\n",
      "        -7.93403453e-02,  1.00251199e-03, -2.11464045e-01,\n",
      "        -2.80290051e-01, -2.81071786e-02,  1.13375472e-05,\n",
      "         2.16483761e-01,  1.68937600e-05,  1.07521356e-01,\n",
      "         1.71414357e-01, -1.24135015e-02,  1.72178755e-07,\n",
      "         1.51217002e-02,  1.10532862e-01,  2.52272793e-01,\n",
      "         1.33153665e-07,  3.43709709e-01, -2.37078571e-01,\n",
      "         4.41985726e-01, -3.29377278e-01,  2.59029957e-01,\n",
      "         1.49719821e-01, -1.88503791e-02, -3.41449911e-02,\n",
      "        -3.26121051e-01, -7.42572115e-03,  2.41682645e-06,\n",
      "         1.70683403e-01, -7.96532983e-02, -1.08895193e-01,\n",
      "        -2.44003453e-01, -3.47817890e-07, -1.29875801e-02,\n",
      "         2.64769737e-01,  3.41866370e-02,  2.81110557e-01,\n",
      "         2.34565711e-01,  1.11061252e-01,  7.12167099e-02,\n",
      "         3.25936731e-01, -2.00249425e-05,  7.57073257e-02,\n",
      "        -7.21731993e-02, -1.27289149e-01,  8.28942423e-02,\n",
      "        -5.15006075e-02, -8.04595793e-02, -3.42836060e-02,\n",
      "        -2.53223293e-01,  3.48658892e-01,  2.09626553e-02,\n",
      "         3.10994161e-01, -5.50548068e-07, -2.57391613e-01,\n",
      "        -1.64230856e-01,  2.77965285e-07,  1.85922776e-01,\n",
      "         2.64116291e-01,  5.62533651e-02,  7.79920688e-02,\n",
      "        -1.44166004e-01, -5.89972211e-02, -3.67947396e-02,\n",
      "         2.91574132e-01,  9.35792895e-02,  1.33979902e-06,\n",
      "        -6.74189759e-07],\n",
      "       [-2.14843047e-01,  1.37718544e-01, -6.43578230e-05,\n",
      "        -2.51188659e-01,  3.41900587e-01,  1.65190893e-01,\n",
      "         2.70929198e-01, -3.30732532e-01,  3.34750495e-01,\n",
      "        -1.01914224e-02,  3.87521563e-02, -1.83254443e-01,\n",
      "         2.56066424e-06, -4.87891526e-06,  1.10390352e-01,\n",
      "        -1.78995798e-03, -7.58545190e-02, -4.47296042e-02,\n",
      "        -2.66587809e-01,  5.41607455e-07,  3.74780010e-01,\n",
      "         2.35171224e-02,  3.17094380e-01,  1.83493882e-01,\n",
      "        -2.29437088e-01, -7.19536375e-02,  7.83605415e-02,\n",
      "         1.42525921e-01,  1.21679378e-01,  6.37882427e-02,\n",
      "         1.51257860e-01, -2.16016445e-01,  4.16900505e-01,\n",
      "        -2.70998896e-02, -8.18533248e-08, -1.84462097e-01,\n",
      "         1.40103690e-01,  2.83481146e-01, -2.25542014e-06,\n",
      "         2.35022754e-01, -7.23556240e-02, -6.62287307e-02,\n",
      "         3.63117020e-01,  1.52247326e-01,  3.70338394e-02,\n",
      "        -7.67637190e-02,  1.88501049e-01,  7.03633427e-02,\n",
      "        -2.51940444e-02,  1.91122706e-01, -3.46990737e-01,\n",
      "         2.39273612e-01, -3.29190014e-01,  1.03895207e-01,\n",
      "         1.09038851e-01,  2.09100995e-01, -2.70596513e-01,\n",
      "        -3.77539334e-01,  1.76978444e-03, -4.55478798e-05,\n",
      "         1.88839610e-01,  1.93785808e-02,  2.81526417e-01,\n",
      "        -2.44153417e-01,  1.02959083e-06,  3.73159889e-01,\n",
      "         2.91854374e-01,  9.49189045e-02,  1.25470142e-02,\n",
      "         3.86821036e-01,  1.37938977e-01,  2.85276754e-01,\n",
      "         3.10909985e-01, -1.16665015e-03,  9.89180446e-02,\n",
      "         1.69732788e-01, -1.56197232e-03, -5.98182090e-02,\n",
      "         1.29986943e-01, -1.22711728e-01,  1.79111046e-01,\n",
      "        -2.27774044e-01,  1.17294576e-01, -2.37889539e-03,\n",
      "        -3.81646250e-02, -1.18539312e-02, -2.56971808e-01,\n",
      "        -3.50849956e-03, -8.17246846e-02, -7.76790606e-02,\n",
      "         1.98682178e-02,  2.49650435e-01,  2.22837244e-01,\n",
      "        -5.26296520e-02,  7.11237002e-02, -5.26923084e-03,\n",
      "         1.76432001e-01, -7.30694170e-02,  3.03100594e-03,\n",
      "        -1.45344165e-06]]), array([[-8.53514501e-02],\n",
      "       [-8.01861785e-02],\n",
      "       [-3.70025698e-03],\n",
      "       [-2.65776766e-01],\n",
      "       [ 1.27899668e-01],\n",
      "       [ 2.67322060e-01],\n",
      "       [ 2.94772531e-01],\n",
      "       [-4.10902994e-01],\n",
      "       [ 2.14804280e-01],\n",
      "       [-4.21031459e-02],\n",
      "       [-1.51905310e-06],\n",
      "       [-4.40408972e-01],\n",
      "       [ 2.46455611e-07],\n",
      "       [-1.07224780e-07],\n",
      "       [-5.27545834e-02],\n",
      "       [-2.31713281e-07],\n",
      "       [ 8.30765845e-08],\n",
      "       [-8.44604901e-02],\n",
      "       [-4.60121534e-01],\n",
      "       [ 1.27450041e-01],\n",
      "       [ 1.37943071e-01],\n",
      "       [ 2.21758300e-02],\n",
      "       [ 3.87886286e-01],\n",
      "       [ 2.04785754e-02],\n",
      "       [-1.49154433e-01],\n",
      "       [-1.43878779e-03],\n",
      "       [-2.13852386e-01],\n",
      "       [-8.92474061e-02],\n",
      "       [ 3.22664457e-01],\n",
      "       [-1.06043226e-01],\n",
      "       [ 3.70401863e-01],\n",
      "       [-4.62336515e-01],\n",
      "       [ 1.09762700e-01],\n",
      "       [ 8.63774045e-05],\n",
      "       [ 6.75713579e-02],\n",
      "       [-2.63786023e-01],\n",
      "       [-1.11135379e-01],\n",
      "       [ 1.55337723e-01],\n",
      "       [-2.36149890e-07],\n",
      "       [ 2.87225086e-01],\n",
      "       [-9.08406544e-04],\n",
      "       [-1.08571146e-01],\n",
      "       [ 3.73698247e-01],\n",
      "       [-2.19009106e-02],\n",
      "       [ 5.58285325e-06],\n",
      "       [-1.85980653e-02],\n",
      "       [-2.14921036e-02],\n",
      "       [ 2.65195501e-01],\n",
      "       [-5.02232883e-02],\n",
      "       [ 3.89477085e-01],\n",
      "       [-2.11501879e-01],\n",
      "       [ 1.38775242e-01],\n",
      "       [-3.30061094e-01],\n",
      "       [ 2.67119328e-01],\n",
      "       [ 2.98629691e-02],\n",
      "       [-1.57140377e-01],\n",
      "       [-3.24800565e-01],\n",
      "       [-2.89787274e-01],\n",
      "       [-1.30082211e-02],\n",
      "       [-6.07918293e-02],\n",
      "       [ 3.93712308e-01],\n",
      "       [ 5.85495071e-02],\n",
      "       [ 1.72693368e-01],\n",
      "       [-2.65647948e-01],\n",
      "       [-5.74794121e-02],\n",
      "       [ 2.25535631e-01],\n",
      "       [ 1.45383059e-01],\n",
      "       [-1.08460560e-01],\n",
      "       [ 7.15400746e-02],\n",
      "       [ 1.19949773e-01],\n",
      "       [-1.16106305e-01],\n",
      "       [ 3.86077133e-01],\n",
      "       [ 2.49145971e-01],\n",
      "       [ 4.11906211e-02],\n",
      "       [ 1.32856439e-01],\n",
      "       [-1.21317102e-01],\n",
      "       [-1.09360008e-01],\n",
      "       [-1.44684783e-01],\n",
      "       [ 1.14845616e-01],\n",
      "       [-1.35915247e-01],\n",
      "       [-1.43597547e-01],\n",
      "       [-4.02551973e-01],\n",
      "       [ 3.08496188e-01],\n",
      "       [-2.35634053e-02],\n",
      "       [ 4.17415135e-01],\n",
      "       [-2.29960469e-02],\n",
      "       [-3.15676166e-01],\n",
      "       [-2.21912922e-01],\n",
      "       [-2.28294483e-07],\n",
      "       [-2.23398274e-01],\n",
      "       [ 4.96333822e-02],\n",
      "       [ 2.55009395e-01],\n",
      "       [ 3.84623866e-01],\n",
      "       [-3.22286497e-01],\n",
      "       [-1.23450094e-01],\n",
      "       [-1.03627001e-01],\n",
      "       [ 3.38650033e-01],\n",
      "       [-2.00280670e-01],\n",
      "       [-2.61134947e-02],\n",
      "       [-1.96996449e-02]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mahsa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlp = MLPClassifier() # set the method\n",
    "mlp.fit(X_training, y_training)                    # training\n",
    "y_pred=mlp.predict(X_training)                      # prediction\n",
    "print(y_pred)                                      # show the output\n",
    "print([coef.shape for coef in mlp.coefs_])  # size of synapsis weights\n",
    "print(mlp.coefs_)                                 # synapsis weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now your Turn!\n",
    "### Experiments\n",
    "\n",
    "-  Change the data (X_training, y_training, X_testing)\n",
    "-  Change the hidden layer of MLP: number of layers (int) or size (n,m)\n",
    "-  Change activation function of MLP: {'identity', 'logistic', 'tanh', 'relu'}, default 'relu'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mahsa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np\n",
    "\n",
    "X_training=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            1,\n",
    "            1,\n",
    "            0\n",
    "           ]\n",
    "X_testing = X_training\n",
    "y_true = y_training\n",
    "mpl = MLPClassifier(activation = 'identity')\n",
    "mpl.fit(X_training,y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n",
      "acuracy= 0.75\n",
      "[(2, 100), (100, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mahsa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(200,100,300 ), activation='logistic') # set the method\n",
    "mlp.fit(X_training, y_training)                    # training\n",
    "y_pred=mlp.predict(X_testing)                      # prediction\n",
    "print(y_pred)                                      # show the output\n",
    "accuracy=metric.accuracy_score(np.array(y_true).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "print('accuracy=',accuracy)                         # show accuracy score\n",
    "\n",
    "\n",
    "print([coef.shape for coef in mlp.coefs_])  # size of synapsis weights\n",
    "len(mlp.coefs_)                                  # synapsis weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XNOR \n",
    "Try solve the following Boolean Exclusive Not Or (XNOR) problem. How to improve the accuracy? How many minimum hidden layer is needed to make it 100% accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            0,\n",
    "            0,\n",
    "            0\n",
    "           ]\n",
    "X_testing=X_training\n",
    "y_true=y_training\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50)) # set the method\n",
    "mlp.fit(X_training, y_training)                    # training\n",
    "                                      # show the output\n",
    "accuracy=metric.accuracy_score(np.array(y_true).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "print('accuracy=',accuracy)                         # show accuracy score\n",
    "\n",
    "\n",
    "print([coef.shape for coef in mlp.coefs_])  # size of synapsis weights\n",
    "len(mlp.coefs_)                                  # synapsis weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mahsa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"iris.csv\")\n",
    "features = train.columns[:-1]\n",
    "X = train[features]\n",
    "Y =train['Species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5)\n",
    "nn = MLPClassifier()\n",
    "a = nn.fit(X_train,y_train)\n",
    "# Returns the mean accuracy on the given test data and labels. \n",
    "nn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "Creat your network based on only two features of the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mahsa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9466666666666667"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your answer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"iris.csv\")\n",
    "features = train.columns[:-1]\n",
    "X = train[features]\n",
    "Y =train['Species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5)\n",
    "nn = MLPClassifier()\n",
    "a = nn.fit(X_train,y_train)\n",
    "nn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to create and train a neural network for a given dataset with higher accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"iris.csv\")\n",
    "features = train.columns[:-1]\n",
    "X = train[features]\n",
    "Y =train['Species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5)\n",
    "nn = MLPClassifier()\n",
    "a = nn.fit(X_train,y_train)\n",
    "nn.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
